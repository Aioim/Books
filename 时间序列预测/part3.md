æœ¬æ–‡ä»‹ç»æ—¶åºé¢„æµ‹ä»»åŠ¡ä¸­çš„å¸¸è§æ·±åº¦å­¦ä¹ æ–¹æ³•ï¼Œç›®å½•å¦‚ä¸‹ï¼š

1. LSTM
2. Transformer
3. Informer
4. ä¸€äº›é‡è¦çš„åº“

------

## 1. LSTM

æ¨¡å‹çš„åŸºæœ¬ç»“æ„å¦‚ä¸‹ï¼š

```python3
class LSTM(nn.Module):
    def __init__(self, input_size=1, hidden_layer_size=100, output_size=1):
        super().__init__()
        self.hidden_layer_size = hidden_layer_size

        self.lstm = nn.LSTM(input_size, hidden_layer_size)

        self.linear = nn.Linear(hidden_layer_size, output_size)

        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),
                            torch.zeros(1,1,self.hidden_layer_size)) # (num_layers * num_directions, batch_size, hidden_size)

    def forward(self, input_seq):
        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq) ,1, -1), self.hidden_cell)
        predictions = self.linear(lstm_out.view(len(input_seq), -1))
        return predictions[-1]
```

ç½‘ä¸Šæœ‰å¾ˆå¤šä½¿ç”¨LSTMè¿›è¡Œ[æ—¶åºé¢„æµ‹](https://zhida.zhihu.com/search?q=æ—¶åºé¢„æµ‹&zhida_source=entity&is_preview=1)çš„æ•™ç¨‹ï¼Œåœ¨æ­¤ä»‹ç»ä¸€äº›å®ç°æ—¶çš„ç»†èŠ‚é—®é¢˜ï¼š

- [æ•°æ®é¢„å¤„ç†](https://zhida.zhihu.com/search?q=æ•°æ®é¢„å¤„ç†&zhida_source=entity&is_preview=1)é˜¶æ®µå¯ä»¥ç”¨MinMaxScalerç¼©æ”¾ï¼Œæ•ˆæœæ›´å¥½
- è¾“å…¥ä¸€èˆ¬æœ‰ä¸¤ç§å½¢å¼ï¼šä¸€ç§æ˜¯ä»¥ (ğ‘¥ğ‘¡ )ä¸€ç»´å‘é‡ä½œä¸ºæ¯ä¸ªæ—¶é—´æ­¥çš„è¾“å…¥ï¼Œå¦ä¸€ç§åˆ™æ˜¯ä»¥ï¼ˆ ğ‘¥ğ‘¡ ï¼Œå¹´ï¼Œæœˆï¼Œæ—¥ï¼Œæ—¶ï¼Œåˆ†ï¼Œç§’ï¼‰nç»´å‘é‡ä½œä¸ºè¾“å…¥ã€‚
- [å…¨è¿æ¥å±‚](https://zhida.zhihu.com/search?q=å…¨è¿æ¥å±‚&zhida_source=entity&is_preview=1)æ‹¼æ¥åœ¨LSTMçš„æœ€åä¸€ä¸ªå•å…ƒã€‚
- ä¸€èˆ¬ä»…æ”¯æŒå•æ­¥é¢„æµ‹ï¼Œä¾‹å¦‚1ï½80æ—¶é—´æ­¥é¢„æµ‹ç¬¬81æ—¶é—´æ­¥ã€‚å½“ç„¶ï¼ŒæŠŠLSTMæ”¹å†™ä¸ºå¤šæ­¥é¢„æµ‹ä¹Ÿå¯ä»¥ï¼Œå³æ¯æ¬¡é¢„æµ‹å¤šæ­¥ï¼Œä¾‹å¦‚1ï½80æ—¶é—´æ­¥é¢„æµ‹ç¬¬81ï½85æ—¶é—´æ­¥ã€‚
- æ— è®ºæ˜¯å•æ­¥è¿˜æ˜¯å¤šæ­¥ï¼Œå¦‚æœå¸Œæœ›ç»§ç»­å¾€åé¢„æµ‹ï¼Œåˆ™éœ€è¦ç»“åˆteacher-forceæˆ–no-teacher-forceã€‚ä»¥å•æ­¥é¢„æµ‹ä¸ºä¾‹ï¼š
  - teacher-forceï¼šå°†çœŸå®å€¼ä½œä¸ºè¾“å…¥ï¼Œä¾‹å¦‚ç”¨2ï½81æ—¶é—´æ­¥çš„çœŸå®å€¼é¢„æµ‹ç¬¬82ä¸ªã€‚
  - no-teacher-forceï¼šå°†[é¢„æµ‹å€¼](https://zhida.zhihu.com/search?q=é¢„æµ‹å€¼&zhida_source=entity&is_preview=1)ä½œä¸ºè¾“å…¥ï¼Œä¾‹å¦‚ç”¨2ï½80æ—¶é—´æ­¥çš„çœŸå®å€¼æ‹¼æ¥ç¬¬81æ—¶é—´æ­¥çš„é¢„æµ‹å€¼ï¼Œé¢„æµ‹ç¬¬82ä¸ªã€‚

## 2. Transformer

å¯ä»¥å‚è€ƒè¿™ä»½ä»£ç å­¦ä¹ transformeråœ¨æ—¶åºé¢„æµ‹çš„åº”ç”¨ï¼š

[GitHub - oliverguhr/transformer-time-series-prediction: proof of concept for a transformer-based time series prediction modelgithub.com/oliverguhr/transformer-time-series-prediction![img](./assets/v2-9b03d17edb321e40ccef2f008c19f7c9_180x120.jpg)](https://link.zhihu.com/?target=https%3A//github.com/oliverguhr/transformer-time-series-prediction)

- æœ¬è´¨ä¸Šè¯¥ä»£ç ä½¿ç”¨çš„æ˜¯Transformerçš„encoderéƒ¨åˆ†ã€‚
- æ”¯æŒå¤šæ­¥é¢„æµ‹ã€‚
- è¾“å…¥ä¸º1ï½100æ—¶é—´æ­¥ï¼Œå…¶ä¸­æœ€å5ä¸ªæ—¶é—´æ­¥å…¨éƒ¨æ›¿æ¢ä¸º0ï¼Œè¾“å‡ºä¸º1ï½100æ—¶é—´æ­¥çš„çœŸå®å€¼ã€‚

## 3. Informer

å¤§åé¼é¼çš„Informerï¼ŒAAAI 2021 Best Paperæå‡ºçš„æ¨¡å‹ï¼Œæ˜¯å¯¹Transformerçš„æ”¹è¿›ã€‚

é¦–å…ˆä»‹ç»ä¸€ä¸ªæ–°ä»»åŠ¡ï¼ŒLSTFï¼ˆLong Sequence Time-Series Forecastingï¼‰ï¼Œå³é•¿åºåˆ—é¢„æµ‹ä»»åŠ¡ã€‚åˆšåˆšæˆ‘ä»¬æåˆ°çš„LSTMæ¨¡å‹ï¼Œå¾€å¾€ä»¥[æ»‘åŠ¨çª—å£](https://zhida.zhihu.com/search?q=æ»‘åŠ¨çª—å£&zhida_source=entity&is_preview=1)ï¼ˆæˆ–åŠ¨æ€è§£ç ï¼‰çš„å½¢å¼åšé•¿åºåˆ—é¢„æµ‹ï¼Œéšç€æ—¶é—´æ­¥çš„å¢é•¿ï¼Œé¢„æµ‹è¯¯å·®ä¼šé€æ¸æ”¾å¤§ã€‚

![img](./assets/v2-578f4bf9ff88d7595e7632f1cce8a5b0_720w.webp)

Transformerå¯ä»¥åŒæ—¶é¢„æµ‹å¤šæ­¥ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šç¼“è§£äº†è¿™ä¸ªé—®é¢˜ï¼Œä½†æ˜¯Transformerä»ç„¶å­˜åœ¨ä¸€å®šä¸è¶³ï¼Œä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹ä¸‰ç‚¹ï¼š

1. [self attention](https://zhida.zhihu.com/search?q=self+attention&zhida_source=entity&is_preview=1)çš„è®¡ç®—å¤æ‚åº¦ä¸º ğ‘‚(ğ¿2) (æ¯ä¸ªQè¦ä¸Lä¸ªKåš[ç‚¹ä¹˜](https://zhida.zhihu.com/search?q=ç‚¹ä¹˜&zhida_source=entity&is_preview=1)ï¼Œå…±æœ‰Lä¸ªQ)
2. é•¿åºåˆ—ä½œä¸ºè¾“å…¥æ—¶ï¼ŒJä¸ªblockéœ€è¦çš„å†…å­˜ä¸º ğ‘‚(ğ½âˆ—ğ¿2)
3. åŠ¨æ€è§£ç çš„æ—¶é—´å¼€é”€è¿‡å¤§

Informerçš„æ”¹è¿›å¦‚ä¸‹ï¼š

1. æå‡ºProbSparse Self-Attention Mechanismï¼Œå°†[æ—¶é—´å¤æ‚åº¦](https://zhida.zhihu.com/search?q=æ—¶é—´å¤æ‚åº¦&zhida_source=entity&is_preview=1)é™ä½è‡³ ğ‘‚(ğ¿ğ¾ğ‘™ğ‘œğ‘”ğ¿ğ‘„) ,æ³¨æ„ ğ¿ğ¾=ğ¿ğ‘„=ğ¿
2. åœ¨Encoderä¸Šæå‡ºSelf-attention Distillingï¼Œé€å±‚é™ä½è¾“å…¥åºåˆ—çš„é•¿åº¦ï¼Œå°†[ç©ºé—´å¤æ‚åº¦](https://zhida.zhihu.com/search?q=ç©ºé—´å¤æ‚åº¦&zhida_source=entity&is_preview=1)é™ä½è‡³ ğ‘‚((2âˆ’ğœ–)ğ¿ğ‘™ğ‘œğ‘”ğ¿)
3. åœ¨Decoderä¸Šæå‡ºGenerative Inferenceï¼Œä¸€æ¬¡é¢„æµ‹å¤šä¸ªæ—¶é—´æ­¥ï¼ˆå®éªŒä¸­è¾¾åˆ°äº†960ä¸ªæ—¶é—´æ­¥ï¼‰ã€‚

å¯ä»¥å‚è€ƒè¿™ä»½ä»£ç å­¦ä¹ Informerï¼Œæ˜¯ä½œè€…çš„å®˜æ–¹ä»£ç ï¼š

[GitHub - zhouhaoyi/Informer2020: The GitHub repository for the paper "Informer" accepted by AAAI 2021.github.com/zhouhaoyi/Informer2020![img](./assets/v2-427309baeabbe33ae3d140352c1f635c_180x120.jpg)](https://link.zhihu.com/?target=https%3A//github.com/zhouhaoyi/Informer2020)

```text
args.seq_len = 48 # input sequence length of Informer encoder
args.label_len = 24 # start token length of Informer decoder
args.pred_len = 24 # prediction sequence length
```

ä»£ç ä¸­çš„ä»¥ä¸Šå‚æ•°é…ç½®è¡¨ç¤ºï¼š1~48æ—¶é—´æ­¥ä¸ºencoderè¾“å…¥ï¼Œ25ï½72æ—¶é—´æ­¥ä¸º[decoder](https://zhida.zhihu.com/search?q=decoder&zhida_source=entity&is_preview=1)è¾“å…¥ï¼ˆå…¶ä¸­49ï½72æ—¶é—´æ­¥è¢«ç½®ä¸º0ï¼‰ï¼Œ25ï½72æ—¶é—´æ­¥ä¸ºdecoderè¾“å‡ºã€‚å¯ä»¥ç»“åˆç€ä¸‹å›¾æ¥ç†è§£ã€‚

![img](./assets/v2-bd543cbc251132b21d34a8ba27dcc325_720w.webp)

å¦ä¸€ä¸ªå®¹æ˜“æ··æ·†çš„å‚æ•°æ˜¯timeencã€‚timeenc = 0 if args.embed!='timeF' else 1ï¼Œå¦‚æœtimeencä¸º1ï¼Œå°†è€ƒè™‘æ›´å¤šå¯èƒ½çš„å‘¨æœŸä¿¡æ¯ã€‚

**4. ä¸€äº›é‡è¦çš„åº“**

**ä»¥ä¸‹æ˜¯ä¸€äº›å­¦ä¹ è¿‡ç¨‹ä¸­æ¥è§¦åˆ°çš„ã€å…³äºæ—¶åºä»»åŠ¡çš„å¼€æºåº“çš„æ•´ç†ã€‚**

[https://github.com/linkedin/luminol](https://link.zhihu.com/?target=https%3A//github.com/linkedin/luminol)

luminolæ”¯æŒä¸¤å¤§åŠŸèƒ½ï¼šæ—¶åºå¼‚å¸¸æ£€æµ‹ã€ä¸¤æ¡æ—¶é—´åºåˆ—çš„ç›¸å…³æ€§è®¡ç®—ã€‚



[GitHub - jdb78/pytorch-forecasting: Time series forecasting with PyTorch](https://link.zhihu.com/?target=https%3A//github.com/jdb78/pytorch-forecasting)

pytorch-forecastingæ˜¯ä¸€ä¸ªåŸºäºpytorchçš„æ—¶åºé¢„æµ‹åº“ï¼Œå†…åµŒäº†ä¸€ç³»åˆ—æ¨¡å‹ï¼Œå¦‚LSTMã€DeepARã€Transformerã€N-BEATSç­‰ã€‚



[Anomaly Detection Toolkit (ADTK)](https://link.zhihu.com/?target=https%3A//arundo-adtk.readthedocs-hosted.com/en/stable/)

adtkæä¾›äº†é€šè¿‡ä¸‰å¤§ç»„ä»¶ï¼Œæä¾›åŸºæœ¬çš„[å¼‚å¸¸æ£€æµ‹ç®—æ³•](https://zhida.zhihu.com/search?q=å¼‚å¸¸æ£€æµ‹ç®—æ³•&zhida_source=entity&is_preview=1)ï¼ˆDetectorï¼‰ã€å¼‚å¸¸ç‰¹å¾åŠ å·¥ï¼ˆTransformerï¼‰ã€å¤„ç†æµç¨‹æ§åˆ¶ï¼ˆAggregatorï¼‰ç­‰åŠŸèƒ½ã€‚æ³¨æ„è¿™é‡ŒçœŸçš„åªæ˜¯åŸºæœ¬ç®—æ³•ï¼Œä¾‹å¦‚åœ¨å¼‚å¸¸æ£€æµ‹ä¸­ï¼Œé€šè¿‡é˜ˆå€¼/åˆ†ä½æ•°/æ»‘åŠ¨çª—å£/[è‡ªå›å½’](https://zhida.zhihu.com/search?q=è‡ªå›å½’&zhida_source=entity&is_preview=1)ç­‰æ–¹å¼åˆ¤æ–­å¼‚å¸¸ï¼Œæ²¡æœ‰é«˜çº§çš„æ£€æµ‹æ¨¡å‹ã€‚



[https://github.com/alexminnaar/time-series-classification-and-clustering](https://link.zhihu.com/?target=https%3A//github.com/alexminnaar/time-series-classification-and-clustering)

[https://github.com/FilippoMB/Time-series-classification-and-clustering-with-Reservoir-Computing](https://link.zhihu.com/?target=https%3A//github.com/FilippoMB/Time-series-classification-and-clustering-with-Reservoir-Computing)

[GitHub - wannesm/dtaidistance: Time series distances: Dynamic Time Warping (DTW)](https://link.zhihu.com/?target=https%3A//github.com/wannesm/dtaidistance)

[tslearnâ€™s documentation - tslearn 0.5.1.0 documentation](https://link.zhihu.com/?target=https%3A//tslearn.readthedocs.io/en/stable/)

ä»¥ä¸Šå‡ ä¸ªé¡¹ç›®ä¸æ—¶é—´åºåˆ—èšç±»ä»»åŠ¡ç›¸å…³ã€‚



[GitHub - MaxBenChrist/awesome_time_series_in_python: This curated list contains python packages for time series analysis](https://link.zhihu.com/?target=https%3A//github.com/MaxBenChrist/awesome_time_series_in_python)

æ—¶é—´åºåˆ—ç›¸å…³å·¥å…·ã€æ¨¡å‹ã€æ•°æ®é›†æ±‡æ€»ã€‚