### 1.梯度消失&梯度爆炸概念

梯度消失：**反向传播**时前面层的梯度依赖于后面层梯度的乘积，如果累乘小于1的数，随着层数的增加前面层梯度会呈指数级的趋于0。

梯度爆炸：累乘的数大于1，导致梯度非常大。

### 2.如何判断是否出现梯度消失/爆炸？

梯度消失：

- 模型无法更新、损失函数几乎保持不变

梯度爆炸：

- 模型型不稳定，更新过程中的损失出现显著变化。
- 训练过程中，模型损失变成 NaN。

### 3.出现原因

**梯度消失：**

- 隐藏层的层数过多。
- 采用了不合适的激活函数。

**梯度爆炸：**

- 隐藏层的层数过多。
- 权重的初始化值过大。

### 4.解决方法

(1) 减小网络层数。

(2) 调整学习率，（梯度消失增加、梯度爆炸减小）。

(3) 更换激活函数（ReLU、Leaky ReLU、ELU、SELU等）。

(4) Batch Normalization。

(5) 更换初始化方法。

(6) 使用残差模块 （ResNet）。

(7) RNN更换为LSTM结构。

(8) 梯度裁剪（超过设定阈值其变为值域）。

(9) L1、L2正则化。

(10) 预训练+微调



资料来源：https://zhuanlan.zhihu.com/p/510039572